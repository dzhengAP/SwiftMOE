{
  "configurations": {
    "gpus": 8,
    "experts": 128,
    "d_model": 1024,
    "batch_sizes": [
      512,
      1024,
      2048,
      4096,
      8192
    ]
  },
  "frameworks_tested": [
    "PyTorch (Baseline)",
    "UltimateMoE (Ours)",
    "DeepSpeed-MoE",
    "Megatron-LM"
  ],
  "total_experiments": 40
}